{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Generate BERT Encodings using a pre-trained BERT model\n",
    "\n",
    "We have used https://pypi.org/project/sentence-transformers/\n",
    "to generate the embeddings for our training data. Once these embeddings are done we have trained a classfier using Logistic Regression to validate the notion that we can use pre-trained embeddings for the text of the web pages to classify them as Faculty vs Non Faculty. Please note that any classifier (e.g. XGBoost, SVM etc.) can  be trained using these embedding to improve performance over Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "negative_data = []\n",
    "with open('data/classificationData/negative.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.split(\"#####\")\n",
    "        negative_data.append(data[0].strip())\n",
    "\n",
    "len(negative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6521"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data = []\n",
    "with open('data/classificationData/positive.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.split(\"#####\")\n",
    "        positive_data.append(data[0].strip())\n",
    "\n",
    "len(positive_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3862, 3862)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_x = []\n",
    "combined_data_y = []\n",
    "for data in negative_data:\n",
    "    combined_data_x.append(data)\n",
    "    combined_data_y.append(0)\n",
    "\n",
    "counter = 1\n",
    "for data in positive_data:\n",
    "    if counter <= len(negative_data):\n",
    "        combined_data_x.append(data)\n",
    "        combined_data_y.append(1)\n",
    "    else:\n",
    "        break\n",
    "    counter += 1\n",
    "(len(combined_data_x), len(combined_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined_data, columns =['web-page-text', 'Label'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(combined_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3862"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_function__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.79919106e-01, -1.64380893e-01,  5.04807532e-01, -6.55960143e-01,\n",
       "       -1.06359690e-01, -3.39308739e-01, -2.05850378e-01, -4.57326114e-01,\n",
       "        2.28776149e-02, -2.80305475e-01,  3.03139836e-02,  5.55711329e-01,\n",
       "       -3.34782034e-01,  8.96301150e-01,  6.43501818e-01, -1.44729123e-01,\n",
       "       -5.18683434e-01, -3.15438747e-01,  4.71709892e-02,  1.54703051e-01,\n",
       "        4.61170673e-01,  3.92214179e-01,  1.79433122e-01,  1.25565016e+00,\n",
       "       -9.75942135e-01, -7.91273490e-02,  8.32066238e-02,  1.51156381e-01,\n",
       "        1.72183231e-01,  1.67126596e-01, -4.75989245e-02, -1.69733167e-01,\n",
       "        8.06320086e-02,  3.14925879e-01,  5.76777041e-01,  5.76354973e-02,\n",
       "        8.21184039e-01,  1.11209571e+00,  8.91262472e-01,  4.37721044e-01,\n",
       "       -5.12461543e-01, -1.57487616e-01,  3.25724006e-01,  1.18725586e+00,\n",
       "        2.11626172e-01, -7.04340518e-01,  9.76675376e-02, -5.28942108e-01,\n",
       "       -8.56056809e-01, -4.39239256e-02,  1.34506943e-02, -5.18116295e-01,\n",
       "        4.50337261e-01, -2.88893282e-01, -3.94152761e-01, -4.65467870e-01,\n",
       "        3.39707047e-01, -7.88033724e-01,  2.42491409e-01, -2.61997551e-01,\n",
       "        4.58799928e-01,  2.55212784e-02, -8.11738729e-01, -5.09249032e-01,\n",
       "       -4.07525599e-02, -9.35124010e-02, -2.73250878e-01,  6.05800509e-01,\n",
       "       -1.34562004e+00, -3.16338718e-01, -4.76399176e-02, -1.82521716e-01,\n",
       "       -5.82717001e-01, -7.33059525e-01,  5.46925068e-01, -1.14006960e+00,\n",
       "        1.06420234e-01, -1.17266104e-01,  1.28557041e-01, -1.94370091e-01,\n",
       "       -4.98418026e-02,  5.14915705e-01,  1.92600355e-01,  3.15205306e-01,\n",
       "       -5.03443062e-01,  7.07427979e-01,  1.12060022e+00, -4.38060969e-01,\n",
       "       -1.84002340e-01,  3.44743907e-01, -1.19450770e-01, -3.28916520e-01,\n",
       "        6.90070093e-01, -3.24486822e-01, -6.43890738e-01, -4.17087972e-01,\n",
       "        1.32431284e-01, -5.39287865e-01,  5.31640910e-02,  2.43934840e-01,\n",
       "       -3.52767915e-01,  1.03649652e+00, -1.02076970e-01,  6.47004068e-01,\n",
       "        1.59908477e-02, -3.78187418e-01, -1.83327407e-01, -1.19960956e-01,\n",
       "       -9.81427968e-01,  6.03814311e-02,  8.94104898e-01,  7.08516538e-01,\n",
       "       -1.50901243e-01, -2.63686329e-01, -2.90121257e-01, -1.70971215e+00,\n",
       "       -3.63037400e-02, -1.45610347e-01,  1.23292136e+00,  3.30134183e-01,\n",
       "       -1.39088392e-01,  4.26626176e-01,  9.34709251e-01,  1.88526332e-01,\n",
       "        1.44800439e-01, -7.84073547e-02, -3.70805174e-01,  2.22467154e-01,\n",
       "       -2.81648427e-01, -3.29096839e-02,  6.62484765e-02,  2.10860983e-01,\n",
       "        1.05664022e-02,  3.85436267e-01,  8.96341026e-01, -4.50133264e-01,\n",
       "       -7.87793219e-01, -1.08614653e-01, -6.56462908e-01,  2.62156695e-01,\n",
       "       -9.85627592e-01, -8.12872574e-02,  7.89959729e-01, -3.96089315e-01,\n",
       "        2.86350429e-01, -1.09081054e+00, -1.53191662e+00, -5.76588333e-01,\n",
       "        5.39875664e-02, -5.05265653e-01, -8.56609046e-01,  1.73958138e-01,\n",
       "        8.78314227e-02, -1.08339012e+00,  3.71523261e-01,  7.68179476e-01,\n",
       "        7.51320660e-01, -2.55523443e-01,  7.34453619e-01, -4.04328257e-01,\n",
       "       -8.58732939e-01,  1.19782686e-01, -2.38220021e-01,  7.13473797e-01,\n",
       "        4.19028372e-01,  3.07196043e-02,  2.95293152e-01, -1.20742285e+00,\n",
       "       -6.50862634e-01,  1.64368555e-01, -2.54707277e-01,  1.45292729e-01,\n",
       "        1.04941988e+00, -2.66893566e-01,  8.22157621e-01,  3.62078816e-01,\n",
       "        6.80137038e-01, -3.82659957e-02, -6.44342303e-01, -1.72272131e-01,\n",
       "        8.12151730e-01, -6.29141986e-01, -4.29640450e-02,  3.50772679e-01,\n",
       "       -3.50311756e-01, -2.97230452e-01,  2.78704792e-01, -1.63334429e-01,\n",
       "        2.50955671e-01,  4.51556385e-01,  6.24281228e-01, -2.00876921e-01,\n",
       "       -6.32915676e-01,  4.52135444e-01,  5.92338204e-01,  2.35638469e-01,\n",
       "       -1.76960289e-01,  1.53716481e+00,  1.87318742e-01, -3.64519298e-01,\n",
       "       -1.64850339e-01, -3.86404485e-01, -6.13124192e-01, -1.12624109e-01,\n",
       "       -1.37140453e-01, -2.18639880e-01,  7.34582961e-01,  3.12710971e-01,\n",
       "        6.47399426e-01,  4.63761687e-02,  9.75564495e-02,  8.55053246e-01,\n",
       "        6.43491047e-03, -3.54591995e-01, -6.88676983e-02,  4.91957456e-01,\n",
       "       -5.33757448e-01, -3.55056107e-01, -5.98992467e-01, -2.60219902e-01,\n",
       "        6.41231358e-01, -1.04330905e-01, -9.07220617e-02, -1.93046574e-02,\n",
       "        1.09077740e+00,  1.54733792e-01, -6.24244921e-02, -4.36289877e-01,\n",
       "        4.67270583e-01, -4.22031105e-01,  5.39341718e-02,  3.31383377e-01,\n",
       "       -5.42253330e-02,  4.50537771e-01,  3.40704530e-01, -1.30253285e-01,\n",
       "       -6.61585033e-01, -1.39492369e+00,  5.68570256e-01, -9.89753664e-01,\n",
       "        1.63012594e-01, -3.96932214e-02,  3.97642732e-01,  7.98022747e-02,\n",
       "        5.45251191e-01,  8.39761794e-01,  3.75661463e-01, -5.42393148e-01,\n",
       "        3.02306414e-01,  6.70904934e-01,  5.92273712e-01, -5.26928082e-02,\n",
       "       -8.09867978e-01, -1.23020756e+00, -1.90875694e-01, -1.04189225e-01,\n",
       "        7.38472044e-01, -4.82955337e-01,  4.29270566e-01,  2.33859271e-01,\n",
       "        1.15775175e-01, -1.73572153e-01,  1.12608802e+00, -1.19743161e-02,\n",
       "       -5.60343862e-01,  6.99175596e-02, -8.94799709e-01, -3.47959474e-02,\n",
       "       -1.44099414e-01,  1.82237327e-01, -9.81269658e-01, -3.27320784e-01,\n",
       "        1.44650847e-01,  1.92875713e-01, -2.01207608e-01, -5.43788932e-02,\n",
       "        1.47389889e-01, -3.28314871e-01, -4.87554111e-02,  1.27268898e+00,\n",
       "        2.79302418e-01, -1.61432460e-01,  3.12690318e-01, -1.00190115e+00,\n",
       "       -2.33503938e-01,  4.35729027e-01,  8.02099705e-01, -3.66406143e-01,\n",
       "        5.17803915e-02, -5.26469231e-01,  6.09656930e-01,  4.38580960e-01,\n",
       "       -5.86844146e-01,  9.54678833e-01,  6.79262996e-01, -5.22729993e-01,\n",
       "        6.02344990e-01, -2.38915816e-01,  3.65970433e-01,  2.50772357e-01,\n",
       "       -7.08019137e-01,  8.50464880e-01,  3.13848048e-01,  2.37399518e-01,\n",
       "        2.51977086e-01, -1.14352725e-01,  1.07694566e+00, -7.17923343e-01,\n",
       "       -8.93067867e-02, -3.97811472e-01,  4.00924891e-01, -2.78884977e-01,\n",
       "        5.69121957e-01,  6.91121638e-01, -4.81206886e-02,  3.17521363e-01,\n",
       "        3.39040399e-01, -8.96989286e-01, -1.19341445e+00, -4.63187486e-01,\n",
       "       -9.91520137e-02, -1.20501956e-02,  9.81444240e-01,  1.37649357e+00,\n",
       "        7.81013906e-01,  1.39620388e+00, -4.92748916e-01,  3.88072103e-01,\n",
       "       -1.21785915e+00,  1.66603804e-01,  8.05758238e-01, -2.53823400e-01,\n",
       "        3.16057205e-01,  4.67167765e-01, -7.54027188e-01,  1.53256506e-01,\n",
       "        7.18190297e-02,  2.23855913e-01, -3.57609451e-01,  1.01439285e+00,\n",
       "        9.44006294e-02,  4.80665267e-01, -1.99475288e-01, -2.16283768e-01,\n",
       "       -1.03592969e-01,  4.68088418e-01, -3.17490965e-01,  5.53855777e-01,\n",
       "        1.05522759e-01,  1.20572113e-01, -5.77703714e-01,  4.03097242e-01,\n",
       "        6.82592869e-01, -8.67974162e-01, -4.30856317e-01, -6.85824752e-01,\n",
       "       -2.12714359e-01,  1.44723132e-02,  6.92542017e-01,  4.90965098e-01,\n",
       "        1.86224848e-01,  6.94631100e-01,  9.29456294e-01, -7.51197413e-02,\n",
       "       -5.13399355e-02,  7.56344050e-02, -1.52294600e+00, -1.65081471e-01,\n",
       "        1.93878815e-01,  6.48090065e-01, -2.19940662e-01,  5.54547727e-01,\n",
       "       -8.20382684e-03, -1.02904037e-01,  3.92806791e-02,  2.57687628e-01,\n",
       "        4.34806794e-01,  3.92510682e-01, -9.51873541e-01, -9.11815763e-02,\n",
       "        8.73913884e-01, -7.26327747e-02, -1.70760974e-01,  5.41010499e-01,\n",
       "       -7.70444334e-01, -4.42542918e-02, -1.00934112e+00,  4.29754257e-01,\n",
       "        7.69375443e-01,  7.37015128e-01, -3.84001911e-01, -5.62907517e-01,\n",
       "       -3.26064408e-01, -7.31757104e-01, -4.37321961e-01, -8.19498539e-01,\n",
       "       -9.26976800e-01,  8.34618747e-01, -6.34765387e-01, -5.07719874e-01,\n",
       "        3.44383597e-01,  2.77406387e-02,  8.87188196e-01,  9.69577491e-01,\n",
       "        5.38756251e-02,  1.59281507e-01,  3.66406411e-01,  3.70090336e-01,\n",
       "       -3.76320854e-02, -1.05063617e+00, -8.74895006e-02, -5.18772960e-01,\n",
       "        7.64457043e-03, -3.56598884e-01,  6.99604154e-01, -2.34916285e-01,\n",
       "       -1.38778508e+00, -2.63178289e-01, -1.23909783e+00,  1.01178586e-01,\n",
       "        3.35036159e-01,  2.84400910e-01, -5.45551896e-01, -1.38763655e-02,\n",
       "       -5.21472275e-01, -8.11989084e-02, -2.31254622e-01, -8.17851782e-01,\n",
       "       -8.56469691e-01,  5.23300946e-01, -4.30978119e-01, -2.22695529e-01,\n",
       "        1.55079734e+00,  3.00877333e-01, -8.86358798e-01,  7.82677174e-01,\n",
       "        5.95376372e-01,  4.98683661e-01, -2.18871459e-01, -1.94740027e-01,\n",
       "       -3.91820893e-02,  4.37275209e-02, -4.64006424e-01, -1.77655116e-01,\n",
       "       -7.00434566e-01, -4.60485905e-01,  1.03463419e-01, -7.11141646e-01,\n",
       "       -1.60085544e-01,  7.64852911e-02,  4.33443785e-01, -5.46535492e-01,\n",
       "        5.54570496e-01,  9.06658232e-01,  8.23619187e-01,  1.73953712e-01,\n",
       "       -2.13348847e-02, -8.04868400e-01, -9.28811610e-01, -3.25013459e-01,\n",
       "       -7.52081692e-01, -1.99167058e-01, -7.70590007e-02,  4.53288943e-01,\n",
       "       -2.28883997e-01,  6.73355460e-01,  3.86792660e-01,  2.42856830e-01,\n",
       "        2.75717884e-01, -1.18914604e+00, -2.44089440e-02,  1.87022522e-01,\n",
       "        1.60618141e-01,  4.14265275e-01,  2.09696963e-01, -4.02501523e-01,\n",
       "        2.57730693e-01, -3.54980677e-01, -6.19694352e-01, -1.11672950e+00,\n",
       "        3.45454007e-01, -8.51169407e-01, -6.97196603e-01,  3.75679493e-01,\n",
       "        6.71689510e-01,  7.69134581e-01, -9.16819155e-01,  5.82930148e-01,\n",
       "       -2.03682870e-01, -4.25201118e-01,  2.71598727e-01,  2.00520530e-02,\n",
       "       -7.00485110e-02,  7.98276782e-01,  3.99029672e-01,  3.31080496e-01,\n",
       "       -2.79425621e-01,  8.55319679e-01, -5.66536114e-02, -2.95839496e-02,\n",
       "        1.05949946e-01, -5.19314110e-01,  5.03140807e-01, -2.32730493e-01,\n",
       "        7.64918268e-01, -1.43157542e-01,  2.57232994e-01,  8.08309391e-03,\n",
       "        9.68901515e-01,  1.12243462e+00, -7.17835963e-01,  3.13476086e-01,\n",
       "        6.17238343e-01, -1.15736663e+00, -1.32987788e-03, -1.43078482e-02,\n",
       "       -2.26321131e-01,  2.37422287e-01,  5.08417115e-02,  5.83713651e-01,\n",
       "       -8.67777228e-01, -7.60456562e-01,  3.31219882e-01, -3.13088417e-01,\n",
       "       -3.89015637e-02,  4.17018950e-01, -8.10420990e-01, -1.09435093e+00,\n",
       "       -1.41044751e-01,  3.71568352e-01,  2.92920619e-01, -2.74278969e-01,\n",
       "       -4.73608375e-01,  7.80909896e-01, -1.04526114e+00,  8.03631783e-01,\n",
       "       -1.52936563e-01, -7.25543857e-01,  1.33452606e+00, -2.87571967e-01,\n",
       "       -5.15293777e-01,  7.83243254e-02,  6.57180369e-01, -4.51901138e-01,\n",
       "       -2.70189136e-01, -5.90911627e-01, -1.93654299e-01,  2.55379051e-01,\n",
       "       -9.96470213e-01,  2.18828812e-01,  2.85017699e-01, -2.57025927e-01,\n",
       "       -4.62844223e-01, -6.89797282e-01, -4.76542830e-01, -2.75527000e-01,\n",
       "       -4.31134701e-01, -1.72059849e-01,  2.82078385e-01,  3.75046432e-01,\n",
       "       -8.47192466e-01, -2.72340812e-02,  1.10512525e-01, -2.61971593e-01,\n",
       "        5.93271339e-03, -2.51143187e-01, -4.01905149e-01,  2.60518100e-02,\n",
       "       -9.60965097e-01,  1.10983157e+00, -2.66981810e-01, -1.90822840e-01,\n",
       "       -1.12049150e+00, -5.71107388e-01,  3.15998703e-01, -9.17395055e-01,\n",
       "       -1.01926506e+00, -5.11189818e-01,  5.72344303e-01,  1.03478777e+00,\n",
       "       -8.53399158e-01, -1.38803303e-01,  7.23641813e-02,  4.60701764e-01,\n",
       "        1.96182922e-01,  1.17432058e-01, -1.30700305e-01, -1.45571634e-01,\n",
       "       -4.46526229e-01,  1.12029865e-01, -1.35270679e+00, -4.94014114e-01,\n",
       "        3.40545893e-01, -5.21779835e-01,  1.03548777e+00, -2.42778108e-01,\n",
       "        6.05828106e-01,  3.22269380e-01,  1.09513068e+00,  3.21381062e-01,\n",
       "        7.68926203e-01, -9.68046963e-01,  1.28034223e-02,  9.55327034e-01,\n",
       "        9.83737290e-01, -8.52147996e-01,  6.71689928e-01, -5.10550439e-01,\n",
       "       -4.18957323e-02,  8.06709230e-01,  5.82484245e-01,  8.44442099e-03,\n",
       "       -6.72281114e-03,  5.95447183e-01, -5.35889156e-03,  2.51640230e-01,\n",
       "       -6.18916512e-01, -1.22248101e+00, -4.98349428e-01,  4.31998998e-01,\n",
       "       -5.83219826e-01,  6.21889532e-01, -5.93828142e-01,  7.16321588e-01,\n",
       "        5.81210256e-01, -1.79678530e-01, -4.78169054e-01,  1.72898903e-01,\n",
       "        2.61539370e-01, -3.18311989e-01,  1.65651649e-01, -4.08996314e-01,\n",
       "        6.96318090e-01, -7.45591819e-01, -9.94083107e-01,  1.60425097e-01,\n",
       "       -1.03321373e+00,  3.00940961e-01,  4.75807823e-02, -3.89667526e-02,\n",
       "       -3.45516235e-01, -1.86669916e-01,  2.56272942e-01,  6.82308912e-01,\n",
       "        1.06566763e+00, -4.08705562e-01, -3.01631153e-01,  5.69114566e-01,\n",
       "       -8.23882520e-01,  1.44547343e+00, -6.69994056e-01,  2.37533957e-01,\n",
       "        7.92113990e-02, -6.39966547e-01,  4.37182710e-02,  3.71606410e-01,\n",
       "       -3.35645258e-01, -9.71895584e-04, -4.69659083e-03, -8.15767527e-01,\n",
       "       -8.96274567e-01, -2.37475514e-01,  5.57483554e-01,  8.00591260e-02,\n",
       "        3.38310778e-01,  7.31234848e-01,  4.17826772e-02, -5.48969567e-01,\n",
       "       -1.95476860e-01, -7.64742792e-01,  5.83551489e-02,  8.99564564e-01,\n",
       "       -1.25189495e+00, -4.93317336e-01,  7.39590347e-01, -2.31029004e-01,\n",
       "       -6.62829578e-01, -3.30726326e-01, -1.35006458e-01, -6.20518103e-02,\n",
       "       -7.00618267e-01, -4.09896672e-01, -9.01931584e-01,  4.88759615e-02,\n",
       "       -5.79963803e-01, -9.46384221e-02, -5.22823930e-01,  9.18861628e-01,\n",
       "        7.51032531e-01, -1.63591549e-01,  5.42142391e-01, -1.03780940e-01,\n",
       "       -1.25259653e-01, -2.93940991e-01, -7.64446557e-01,  4.69922066e-01,\n",
       "       -5.23435950e-01, -7.19429612e-01, -9.88900363e-01, -1.69365212e-01,\n",
       "       -1.01490058e-01, -8.24506432e-02, -1.09912775e-01, -9.72362459e-01,\n",
       "       -5.13007492e-02,  4.63097304e-01,  5.59700668e-01,  4.46974903e-01,\n",
       "       -2.77430727e-03, -1.75461555e+00,  8.97675902e-02, -3.25215191e-01,\n",
       "        3.69405121e-01, -4.55091119e-01,  6.19131207e-01,  8.61955360e-02,\n",
       "       -8.83768439e-01,  6.20981455e-01, -1.53807223e-01,  3.26684237e-01,\n",
       "       -1.06274569e+00,  3.44772041e-01, -4.23939787e-02, -7.96294063e-02,\n",
       "       -3.04348171e-01,  1.21676147e-01, -4.76721197e-01, -2.06407666e-01,\n",
       "       -2.70917028e-01, -1.04686171e-01, -2.48409912e-01, -3.13824058e-01,\n",
       "        6.82976365e-01,  9.24126685e-01, -1.72754601e-01, -6.94742501e-02,\n",
       "        7.09915906e-03,  6.72795057e-01,  1.83918104e-01, -2.99986541e-01,\n",
       "       -3.24236780e-01,  2.76122466e-02,  1.58487726e-02, -6.53177917e-01,\n",
       "        5.13950102e-02,  8.05075347e-01, -3.89476895e-01,  3.32942575e-01,\n",
       "       -4.77673084e-01,  2.53071517e-01,  4.65646163e-02,  7.69355237e-01,\n",
       "        1.09216355e-01,  3.23785961e-01,  7.45603144e-01,  1.33968741e-01,\n",
       "       -5.03076673e-01, -1.11801791e+00, -5.47043324e-01, -4.17509824e-01,\n",
       "       -4.08060789e-01,  2.09159046e-01,  5.24215639e-01, -3.34909814e-03,\n",
       "       -1.59192309e-01,  2.49693483e-01,  6.20288253e-02, -5.23295365e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(embeddings, combined_data_y, test_size = 0.2, random_state=42)\n",
    "X_train=np.array(X_train)\n",
    "# Y_train = np.array(Y_train)\n",
    "Y_train\n",
    "# (X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:score: 0.9874055415617129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pushpit/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "    # fit model no training data\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(X_train, Y_train)\n",
    "\n",
    "    y_pred = logisticRegr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    print(f\"F1:score: {f1_score(Y_test, y_pred, average=None)[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(embeddings, open('bert-embeddings-for-classification.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pickle.load(open('bert-embeddings-for-classification.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:score: 0.9874055415617129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pushpit/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(embeddings, combined_data_y, test_size = 0.2, random_state=42)\n",
    "X_train=np.array(X_train)\n",
    "    # fit model no training data\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "print(f\"F1:score: {f1_score(Y_test, y_pred, average=None)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
